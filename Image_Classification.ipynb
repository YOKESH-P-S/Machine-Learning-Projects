{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzZ4p7kUGMK43EIcA1ID0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOKESH-P-S/Machine-Learning-Projects/blob/main/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation, ELU, PReLU\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))  # Resize image to 128x128 pixels\n",
        "            img = img.flatten()  # Flatten image into 1D array\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "def inaccuracy(x):\n",
        "    return (200 - x) * 0.5\n",
        "\n",
        "def accuracy(x):\n",
        "    return x * 0.5\n",
        "\n",
        "def results(nc, nd):\n",
        "    print(\"Number of cats in first 200 results:\", nc)\n",
        "    print(\"Number of dogs in next 200 results:\", nd)\n",
        "    print(\"Percentage accuracy for cat_test data:\", accuracy(nc), \"%\")\n",
        "    print(\"Percentage accuracy for dog_test data:\", accuracy(nd), \"%\")\n",
        "    print(\"Percentage inaccuracy for cat_test data:\", inaccuracy(nc), \"%\")\n",
        "    print(\"Percentage inaccuracy for dog_test data:\", inaccuracy(nd), \"%\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "cat_data = load_images_from_folder('cat')\n",
        "dog_data = load_images_from_folder('dog')\n",
        "\n",
        "num_images = min(len(cat_data), len(dog_data))\n",
        "cat_data = cat_data[:num_images]\n",
        "dog_data = dog_data[:num_images]\n",
        "\n",
        "cat_train, cat_test = train_test_split(cat_data, test_size=0.2, random_state=42)\n",
        "dog_train, dog_test = train_test_split(dog_data, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = np.concatenate((np.ones(len(cat_train)), np.zeros(len(dog_train))))\n",
        "y_test = np.concatenate((np.ones(len(cat_test)), np.zeros(len(dog_test))))\n",
        "\n",
        "train_data = np.vstack((cat_train, dog_train))\n",
        "test_data = np.vstack((cat_test, dog_test))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_data = scaler.fit_transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "\n",
        "activation_functions = [\n",
        "    'logistic',\n",
        "    'relu',\n",
        "    'tanh',\n",
        "    LeakyReLU(alpha=0.01),\n",
        "    ELU(alpha=1.0),\n",
        "    Activation('swish'),\n",
        "    PReLU()\n",
        "]\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "\n",
        "for activation_function in activation_functions:\n",
        "  if activation_function==\"relu\": #Custom Activation function\n",
        "     if isinstance(activation_function, str):\n",
        "       clf = MLPClassifier(hidden_layer_sizes=(500, 500), activation='relu', solver='adam', max_iter=10000)\n",
        "     else:\n",
        "       clf = MLPClassifier(hidden_layer_sizes=(500, 500), activation=\"tanh\", solver='adam', max_iter=10000)\n",
        "       clf.activation = \"tanh\"\n",
        "     clf.fit(train_data, y_train)\n",
        "     y_result = clf.predict(test_data)\n",
        "\n",
        "nc = np.sum(y_result[:200] > 0.5)\n",
        "nd = np.sum(y_result[200:] < 0.5)\n",
        "\n",
        "print(f\"Results for activation function: {activation_function}\")\n",
        "results(nc, nd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YfQ7n2MfDlH",
        "outputId": "99e9db0b-331c-4028-e68c-309958be9896"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for activation function: <keras.src.layers.activation.prelu.PReLU object at 0x7b7677d41bd0>\n",
            "Number of cats in first 200 results: 117\n",
            "Number of dogs in next 200 results: 111\n",
            "Percentage accuracy for cat_test data: 58.5 %\n",
            "Percentage accuracy for dog_test data: 55.5 %\n",
            "Percentage inaccuracy for cat_test data: 41.5 %\n",
            "Percentage inaccuracy for dog_test data: 44.5 %\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "cat_data = load_images_from_folder('cat')\n",
        "dog_data = load_images_from_folder('dog')\n",
        "\n",
        "num_images = min(len(cat_data), len(dog_data))\n",
        "cat_data = cat_data[:num_images]\n",
        "dog_data = dog_data[:num_images]\n",
        "\n",
        "split_point = int(0.8 * num_images)\n",
        "cat_train, cat_test = cat_data[:split_point], cat_data[split_point:]\n",
        "dog_train, dog_test = dog_data[:split_point], dog_data[split_point:]\n",
        "\n",
        "train_data = np.vstack((cat_train, dog_train))\n",
        "train_labels = np.array([0] * split_point + [1] * split_point)\n",
        "\n",
        "test_data = np.vstack((cat_test, dog_test))\n",
        "test_labels = np.array([0] * (num_images - split_point) + [1] * (num_images - split_point))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_data_reshaped = train_data.reshape(train_data.shape[0], -1)\n",
        "train_data_scaled = scaler.fit_transform(train_data_reshaped)\n",
        "\n",
        "test_data_reshaped = test_data.reshape(test_data.shape[0], -1)\n",
        "test_data_scaled = scaler.transform(test_data_reshaped)\n",
        "\n",
        "train_data = train_data.astype('float32') / 255.0\n",
        "test_data = test_data.astype('float32') / 255.0\n",
        "\n",
        "train_data = train_data.reshape(-1, 128, 128, 1)\n",
        "test_data = test_data.reshape(-1, 128, 128, 1)\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "  MaxPooling2D((2, 2)),\n",
        "  Conv2D(64, (3, 3), activation='relu'),\n",
        "  MaxPooling2D((2, 2)),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "history = model.fit(datagen.flow(train_data, train_labels, batch_size=32),\n",
        "                    epochs=5,\n",
        "                    validation_data=(test_data, test_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "print('Train Loss:', history.history['loss'][-1])\n",
        "print('Train Accuracy:', history.history['accuracy'])\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "print(predictions.T)\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "print(predicted_labels.T)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\"Accuracy on test set (manual calculation): {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APHtbtR58YS2",
        "outputId": "eb118a55-2b53-4fd3-e3c3-04b6d29402bd"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 44s 857ms/step - loss: 0.7227 - accuracy: 0.5075 - val_loss: 0.6905 - val_accuracy: 0.5100\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 43s 859ms/step - loss: 0.6855 - accuracy: 0.5575 - val_loss: 0.6862 - val_accuracy: 0.5150\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 44s 886ms/step - loss: 0.6833 - accuracy: 0.5781 - val_loss: 0.6677 - val_accuracy: 0.6325\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 43s 870ms/step - loss: 0.6801 - accuracy: 0.5788 - val_loss: 0.6707 - val_accuracy: 0.6150\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 43s 865ms/step - loss: 0.6719 - accuracy: 0.5906 - val_loss: 0.6725 - val_accuracy: 0.5550\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 0.6725 - accuracy: 0.5550\n",
            "Test accuracy: 0.5550000071525574\n",
            "Test loss: 0.672507643699646\n",
            "Train Loss: 0.6719188690185547\n",
            "Train Accuracy: [0.5074999928474426, 0.5575000047683716, 0.578125, 0.5787500143051147, 0.590624988079071]\n",
            "13/13 [==============================] - 2s 171ms/step\n",
            "[[0.6696464  0.54433864 0.6457978  0.6352608  0.31954825 0.43573073\n",
            "  0.40049088 0.6199281  0.59528565 0.53331316 0.60771084 0.5555996\n",
            "  0.5550924  0.6241083  0.60294664 0.5597938  0.43294498 0.52207375\n",
            "  0.64710945 0.6475942  0.52351743 0.5995288  0.50599605 0.5805473\n",
            "  0.52375597 0.5161998  0.5992456  0.51432997 0.5077753  0.5620659\n",
            "  0.5678337  0.54847884 0.42411703 0.5870185  0.5606917  0.5250691\n",
            "  0.6512323  0.5642854  0.3650035  0.60551256 0.68629086 0.55859935\n",
            "  0.5696524  0.66122425 0.6228766  0.5467531  0.62749404 0.5144686\n",
            "  0.57073414 0.5441179  0.5719001  0.5890103  0.46917307 0.6169145\n",
            "  0.56928796 0.53201437 0.6603649  0.41735488 0.523847   0.61603004\n",
            "  0.29697475 0.5899663  0.14725132 0.6043325  0.38265035 0.6323652\n",
            "  0.50950426 0.7508944  0.58303124 0.5717227  0.5974525  0.55072206\n",
            "  0.5864632  0.4698223  0.5835237  0.65056455 0.54914516 0.5699685\n",
            "  0.5449893  0.5271204  0.70015925 0.48711988 0.6409392  0.54984057\n",
            "  0.62337697 0.5521744  0.6484789  0.5933974  0.451231   0.63412535\n",
            "  0.19375105 0.41705114 0.60661095 0.6217307  0.42739397 0.5107231\n",
            "  0.5723963  0.547818   0.6179409  0.5484135  0.55347687 0.669566\n",
            "  0.49745604 0.574168   0.50763345 0.42086035 0.48622042 0.4801712\n",
            "  0.5230715  0.50286347 0.56792384 0.5708564  0.45026457 0.65830845\n",
            "  0.6294345  0.409345   0.48022106 0.55857366 0.45429528 0.59486717\n",
            "  0.49492496 0.61892134 0.5555461  0.39781526 0.6182177  0.6113597\n",
            "  0.5948699  0.52869207 0.5624741  0.63944554 0.5637043  0.49457192\n",
            "  0.59941024 0.6388332  0.36724675 0.58509785 0.5311069  0.54371697\n",
            "  0.628062   0.608273   0.58900374 0.5004825  0.47288465 0.6217158\n",
            "  0.4679055  0.59713155 0.5546961  0.53989834 0.62296623 0.5628395\n",
            "  0.6784807  0.69317335 0.4894514  0.69331604 0.49545726 0.56301785\n",
            "  0.50935376 0.5339688  0.5086207  0.5756605  0.55388874 0.4699329\n",
            "  0.58239746 0.55872893 0.5224158  0.5976061  0.64424545 0.45398238\n",
            "  0.5685067  0.59555    0.42189932 0.5625056  0.5978776  0.5153234\n",
            "  0.67855257 0.5358525  0.6024982  0.60965896 0.6223752  0.5420085\n",
            "  0.37778845 0.61221915 0.6120846  0.57371134 0.56299907 0.57403964\n",
            "  0.39833722 0.5377321  0.543337   0.6529776  0.42380136 0.6105592\n",
            "  0.55277467 0.64179397 0.58901256 0.6753248  0.5523529  0.61660224\n",
            "  0.49837908 0.48532    0.85430574 0.74232745 0.62942773 0.7232076\n",
            "  0.65425813 0.5875614  0.6843358  0.59067196 0.53099227 0.51684564\n",
            "  0.34163925 0.5267321  0.6275967  0.7471527  0.61122745 0.6296218\n",
            "  0.56091666 0.63363856 0.74485385 0.6410416  0.5980333  0.53353775\n",
            "  0.6036302  0.5640198  0.7006619  0.60162634 0.57429135 0.61093813\n",
            "  0.51385003 0.6409633  0.49524218 0.6972123  0.68901664 0.6224206\n",
            "  0.7501805  0.6137073  0.49633828 0.5529047  0.6176017  0.6300684\n",
            "  0.59852844 0.58286995 0.6923104  0.60987675 0.5878309  0.6275409\n",
            "  0.5828723  0.6230566  0.5851452  0.66598433 0.60362554 0.75624883\n",
            "  0.5912575  0.6230373  0.5803631  0.5361093  0.60372686 0.6964765\n",
            "  0.67927784 0.6090539  0.7208761  0.5768198  0.53201157 0.62915206\n",
            "  0.4443981  0.6664175  0.5286931  0.48017094 0.5945767  0.56135064\n",
            "  0.3517758  0.745905   0.6589294  0.58503026 0.46847445 0.5719684\n",
            "  0.6046753  0.5550542  0.59397256 0.5802154  0.5520267  0.6451806\n",
            "  0.5944317  0.5928354  0.67703056 0.6177131  0.41080657 0.5775483\n",
            "  0.6111794  0.5564315  0.5734014  0.54935163 0.5519725  0.5632511\n",
            "  0.6673113  0.5584274  0.7006795  0.5212572  0.55976856 0.5518406\n",
            "  0.57789946 0.77879256 0.6021755  0.6959557  0.5739386  0.5906993\n",
            "  0.6743104  0.61516124 0.64806587 0.5595134  0.59010744 0.42269987\n",
            "  0.51200986 0.73898417 0.62354326 0.6829929  0.68446636 0.35516638\n",
            "  0.62114215 0.3056697  0.6832834  0.61327374 0.627148   0.6258563\n",
            "  0.31875494 0.62015826 0.6122378  0.613927   0.47884366 0.65112966\n",
            "  0.60121346 0.614667   0.5826676  0.6667769  0.5296226  0.62878203\n",
            "  0.47889292 0.6471657  0.3457481  0.58318245 0.6988787  0.58292526\n",
            "  0.5141996  0.57169956 0.6725564  0.58282685 0.7030885  0.5813279\n",
            "  0.63609254 0.62550783 0.5946233  0.74464214 0.76615787 0.36057296\n",
            "  0.6454285  0.72322875 0.58903754 0.45267314 0.64813954 0.6712379\n",
            "  0.6785522  0.6236829  0.64052457 0.62035036 0.5654944  0.5888139\n",
            "  0.5126243  0.551634   0.6623861  0.573984   0.6240413  0.57554865\n",
            "  0.6826949  0.58601356 0.60738516 0.6213956  0.5163438  0.5746397\n",
            "  0.61167616 0.58986855 0.59094757 0.567433   0.6203903  0.30267543\n",
            "  0.7548474  0.5940482  0.54448956 0.4967808  0.61621517 0.63214576\n",
            "  0.54998916 0.5217961  0.55972445 0.6204822  0.6220846  0.6297609\n",
            "  0.61151505 0.69705254 0.7458256  0.57323647]]\n",
            "[[1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            "  1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
            "  1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0\n",
            "  1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            "  0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
            "  0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1\n",
            "  0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1]]\n",
            "Accuracy on test set (manual calculation): 0.555\n"
          ]
        }
      ]
    }
  ]
}